# -*- coding: utf-8 -*-
"""GAT_Text_Reading.ipynb

Automatically generated by Colaboratory.


# **Text Extraction using Google colab**

## Description

In this script I try to extract the text from multiple documents already downloaded.

We have 5 types of documents to read
*   XML
*   PDF
*   TXT
*   EXCEL
*   WORD

## **0. Preamble**
"""

import os
# os.kill(os.getpid(), 9)

# !apt-get install ocrmypdf -q

!apt-get install poppler-utils 
!apt-get install tesseract-ocr
!pip install -U -q PyDrive
!pip install pdfminer -q
!pip install pdfminer.six
!pip install pdf2image
!pip install pytesseract -q

from google.colab import drive
drive.mount('/content/gdrive')

from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage
from io import StringIO
from os import listdir
from os.path import isfile, join
import glob
import re
import sys
import pandas as pd
import pytesseract
from pdf2image import convert_from_path
import cv2
from PIL import Image

# paths
pdf_path = "PDFs"
txt_path = "PDF txt"

"""## **1. Starting with the pdfs**"""

#List of all pdfs in directory
pdf_list = [re.sub(pdf_path,'',i) for i in (glob.glob(join(pdf_path,'*.pdf')))]
pdf_list = [re.sub(r'\/','',i) for i in pdf_list]

pdf_list[0]

"""#### 1.1 Function that converts pdf to text"""

def convert_pdf_to_txt(path):
    rsrcmgr = PDFResourceManager()
    retstr = StringIO()
    codec = 'utf-8'
    laparams = LAParams()
    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
    fp = open(path, 'rb')
    interpreter = PDFPageInterpreter(rsrcmgr, device)
    password = ""
    maxpages = 0
    caching = True
    pagenos=set()

    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):
        interpreter.process_page(page)

    text = retstr.getvalue()

    fp.close()
    device.close()
    retstr.close()
    return text

"""#### 1.2 Extracting the text 

Three types of PDF: pdf_category


*   pdf_category = 0 -> not possible to open
*   pdf_category = 1 -> extractable as text
*   pdf_category = 2 -> scanned OCR'd
"""

join(txt_path,pdf_list[0])

"""##### 1.2.1 PDFs text searchable"""

pdf_category = []

#loop over all documents
for doc in pdf_list[0:50]:
    try:
        text = convert_pdf_to_txt(join(pdf_path,doc))
        #eliminate control characters, they're not useful
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\xff]','', text)
        doc_name_txt = re.sub(".pdf",".txt",doc)

        #if len text = 0 is scanned -> OCR
        # if is not 0 then extract it with the following function

        #OCR -> I'll run this after bc this takes a lot of time
        if len(text)== 0:
            pdf_category.append(2)

        #USUAL TEXT EXTRACTION
        else:
            with open(join(txt_path,doc_name_txt), mode = "w", encoding = "utf-8") as f_text:
                f_text.write(text)

            pdf_category.append(1)

    except:
        print("File: ", doc, " is not readable")
        pdf_category.append(0)

#we create a database with the pdf - category
PDF_cat_dict = {'PDF': pdf_list[0:50], 'category': pdf_category}

PDF_database = pd.DataFrame(PDF_cat_dict)
PDF_database.to_csv('PDF_TextExtraction_Results.csv')

"""##### 1.2.2 OCR pdfs that are scanned"""

#list of OCR documents
pdf_list_OCR = PDF_database[PDF_database['category'] == 2]['PDF'].tolist()

pdf_list_OCR

for doc in pdf_list_OCR:

    #name for new txt file
    doc_name_txt = re.sub(".pdf",".txt",doc)
    #new txt file to append result from pages
    open(join(txt_path,doc_name_txt), mode = "w", encoding = "utf-8")
    
    #first to image
    pages = convert_from_path(join(pdf_path,doc), 350)

    #loop extracting text from each page
    i = 1    
    for page in pages:
        image_name = "Page_" + str(i) + ".jpg"
        page.save(image_name, "JPEG")
        i = i+1
        image = cv2.imread(image_name)
        text_ocr_page = str(pytesseract.image_to_string(image))
        text_ocr_page = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\xff]','', text_ocr_page)

        with open(join(txt_path,doc_name_txt), mode = "a", encoding = "utf-8") as f_text:
            f_text.write(text_ocr_page)
